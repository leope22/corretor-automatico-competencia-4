# An√°lise e Avalia√ß√£o Autom√°tica da Compet√™ncia 4 de Reda√ß√µes do ENEM

Este projeto realiza uma investiga√ß√£o sobre os elementos de coes√£o textual em reda√ß√µes e desenvolve m√∫ltiplos modelos de Machine Learning para prever a nota da Compet√™ncia 4, que avalia o conhecimento dos mecanismos lingu√≠sticos necess√°rios para a constru√ß√£o da argumenta√ß√£o.

## ‚ö† Visualiza√ß√£o do Notebook

O GitHub apresentou problemas para renderizar o notebook com as sa√≠das devido aos widgets interativos. Para uma visualiza√ß√£o completa, com todos os gr√°ficos e sa√≠das:

1.  Acesse o site **[nbviewer.org](https://nbviewer.org/)**.
2.  Cole o seguinte link do notebook na caixa de pesquisa e pressione Enter:
    ```
    https://github.com/leope22/corretor-automatico-competencia-4/blob/92e3057760362b8f0fe7b4b70906df526d86e3e4/Compet%C3%AAncia_4.ipynb
    ```

## üìú Contexto do Projeto

A Compet√™ncia 4 do Exame Nacional do Ensino M√©dio (ENEM) exige o uso articulado de um repert√≥rio coeso de conectivos e refer√™ncias para construir um texto fluido e bem argumentado. Este projeto busca entender quais caracter√≠sticas textuais est√£o mais correlacionadas com notas altas e, a partir disso, construir um sistema de avalia√ß√£o autom√°tica.

## üî¨ An√°lise Explorat√≥ria de Dados

Antes da modelagem, foi realizada uma extensa an√°lise de dados para extrair features e identificar padr√µes. As principais frentes de investiga√ß√£o foram:

  * **Uso de Conectivos:** An√°lise da quantidade, diversidade e categorias sem√¢nticas dos conectivos utilizados.
  * **Adequa√ß√£o dos Conectivos:** Utiliza√ß√£o de um modelo BERT (Masked Language Model) para verificar se os conectivos foram empregados em contextos semanticamente apropriados.
  * **Riqueza Lexical e Repeti√ß√£o:** Medi√ß√£o da repeti√ß√£o de palavras de conte√∫do em "janelas deslizantes" para avaliar a fluidez do vocabul√°rio.
  * **Estrutura Paragrafal:** An√°lise do n√∫mero, tamanho m√©dio e equil√≠brio dos par√°grafos.

## ü§ñ Modelos Desenvolvidos

Foram implementadas e avaliadas tr√™s abordagens progressivamente mais complexas:

### 1\. Avaliador Baseado em Regras

Um sistema de pontua√ß√£o heur√≠stico que atribui notas com base em m√©tricas extra√≠das da an√°lise (diversidade de conectivos, tamanho dos par√°grafos, taxa de repeti√ß√£o, etc.). Serviu como um baseline para o projeto.

### 2\. Modelo LightGBM com Feature Engineering

Um modelo de Gradient Boosting (LightGBM) treinado com um conjunto robusto de features extra√≠das de forma segmentada (introdu√ß√£o, D1, D2, conclus√£o), incluindo m√©tricas de coes√£o, vocabul√°rio e similaridade sem√¢ntica entre par√°grafos. O modelo demonstrou ser superior ao sistema de regras, especialmente na identifica√ß√£o de reda√ß√µes de nota 200.

### 3\. Modelo BERT com Pondera√ß√£o de Classes (Melhor Performance)

A abordagem final utilizou o fine-tuning de um modelo Transformer pr√©-treinado em portugu√™s, o `neuralmind/bert-base-portuguese-cased`. Diferente dos anteriores, o BERT processa o texto bruto, aprendendo a interpretar o contexto e as nuances sem√¢nticas. Foi utilizada uma t√©cnica de pondera√ß√£o de classes para mitigar o desbalanceamento do dataset.

  * **Resultado:**
      * **Precis√£o Final: 53.8%**, um avan√ßo consider√°vel em rela√ß√£o √†s abordagens anteriores, demonstra uma boa capacidade de acerto.
      * **Recall para Nota 200: 82%**, demonstrando a principal for√ßa do modelo: identificar com alta confian√ßa as reda√ß√µes de m√°xima performance.
      * **Desafio:** O modelo ainda apresenta dificuldade em classificar as notas minorit√°rias (0 e 40), o que √© esperado dada a baixa representatividade delas no dataset.

## üõ†Ô∏è Tecnologias Utilizadas

  * **Linguagem:** Python
  * **An√°lise de Dados:** Pandas, NumPy, Matplotlib, Seaborn
  * **Processamento de Linguagem Natural (NLP):** spaCy, Transformers (Hugging Face)
  * **Machine Learning:** Scikit-learn, LightGBM, Imbalanced-learn
  * **Deep Learning:** PyTorch
